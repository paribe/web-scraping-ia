import streamlit as st
import json
import os
import sys
import pandas as pd

# PRIMEIRO: Configurar p√°gina (deve ser a primeira linha Streamlit)
st.set_page_config(
    page_title="Web Scraping com IA", 
    layout="wide",
    page_icon="‚öΩ"
)

# Configurar o caminho para encontrar os m√≥dulos
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir) if 'interface' in current_dir else current_dir
exemplos_dir = os.path.join(parent_dir, 'exemplos')

# Adicionar diret√≥rios ao sys.path
if parent_dir not in sys.path:
    sys.path.insert(0, parent_dir)
if exemplos_dir not in sys.path:
    sys.path.insert(0, exemplos_dir)

# Configurar a API key usando st.secrets (para Streamlit Cloud)
def carregar_api_key():
    """Carrega a API key usando st.secrets ou arquivo .env local"""
    
    # M√©todo 1: Streamlit Secrets (produ√ß√£o)
    try:
        api_key = st.secrets["OPENAI_API_KEY"]
        if api_key and len(api_key) > 20:
            return api_key
    except:
        pass
    
    # M√©todo 2: Arquivo .env (desenvolvimento local)
    caminhos_env = [
        os.path.join(parent_dir, '.env'),
        os.path.join(current_dir, '.env'),
        os.path.join(os.getcwd(), '.env'),
        '.env'
    ]
    
    # Tentar decouple config primeiro
    try:
        from decouple import config
        api_key = config('OPENAI_API_KEY', default=None)
        if api_key and len(api_key) > 20:
            return api_key
    except:
        pass
    
    # Ler arquivo .env manualmente
    for caminho in caminhos_env:
        if os.path.exists(caminho):
            try:
                with open(caminho, 'r', encoding='utf-8') as f:
                    for linha in f:
                        linha = linha.strip()
                        if linha.startswith('OPENAI_API_KEY='):
                            api_key = linha.split('=', 1)[1].strip().strip('"\'')
                            if len(api_key) > 20:
                                return api_key
            except Exception:
                continue
    
    return None

# Carregar API key
api_key = carregar_api_key()
if api_key:
    os.environ['OPENAI_API_KEY'] = api_key
    api_key_configurada = True
else:
    api_key_configurada = False

st.title("‚öΩ Web Scraping com IA usando LangChain")

opcao = st.selectbox(
    "Escolha o tipo de scraping:",
    ("Tabela do Brasileir√£o", "A√ß√µes (Big Caps)", "Agente inteligente")
)

def formatar_tabela_brasileirao(resultado):
    """Formatar dados do Brasileir√£o PRESERVANDO a ordem original"""
    if not resultado:
        return None
    
    # Filtrar apenas dados v√°lidos de times
    dados_validos = []
    for item in resultado:
        if isinstance(item, dict) and item.get('time') and item.get('time') != 'nan' and item.get('time').strip():
            dados_validos.append(item)
    
    if not dados_validos:
        return None
    
    # Converter para DataFrame SEM alterar a ordem
    df = pd.DataFrame(dados_validos)
    
    # Garantir que as colunas existam e tenham valores padr√£o
    colunas_esperadas = {
        'posicao': 0,
        'time': 'N/A',
        'jogos': 0,
        'vitorias': 0,
        'empates': 0,
        'derrotas': 0,
        'gols_pro': 0,
        'gols_contra': 0,
        'saldo_gols': 0,
        'pontos': 0
    }
    
    for col, default_value in colunas_esperadas.items():
        if col not in df.columns:
            df[col] = default_value
        else:
            # Limpar valores nan e inv√°lidos
            df[col] = df[col].fillna(default_value)
            if col != 'time':
                df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)
    
    # Reordenar colunas
    df = df[list(colunas_esperadas.keys())]
    
    # Remover linhas com time inv√°lido
    df = df[df['time'].str.len() > 2]
    df = df[df['time'] != 'N/A']
    
    # PRESERVAR A ORDEM ORIGINAL - apenas resetar o √≠ndice
    df = df.reset_index(drop=True)
    
    # Renomear colunas para exibi√ß√£o
    df.columns = ['Pos', 'Time', 'J', 'V', 'E', 'D', 'GP', 'GC', 'SG', 'Pts']
    
    return df

def formatar_artilharia(resultado):
    """Formatar dados de artilharia usando extra√ß√£o espec√≠fica"""
    try:
        # Importar o m√≥dulo de artilharia
        artilharia_path = os.path.join(parent_dir, 'artilharia.py')
        
        # Se o arquivo n√£o existir, retornar None
        if not os.path.exists(artilharia_path):
            return None
        
        # Importar e usar a fun√ß√£o de artilharia
        import sys
        sys.path.append(parent_dir)
        import artilharia
        
        urls = ['https://ge.globo.com/futebol/brasileirao-serie-a/']
        dados_artilharia = artilharia.scrape_artilharia(urls)
        
        if dados_artilharia and len(dados_artilharia) > 0:
            df = pd.DataFrame(dados_artilharia)
            # Renomear colunas para melhor exibi√ß√£o
            if 'jogador' in df.columns:
                df = df.rename(columns={
                    'posicao': 'Pos',
                    'jogador': 'Jogador', 
                    'time': 'Time',
                    'gols': 'Gols',
                    'posicao_campo': 'Posi√ß√£o'
                })
            return df
    except Exception as e:
        print(f"Erro ao carregar artilharia: {e}")
    
    return None

# REMOVIDO o par√¢metro type="primary" para compatibilidade
executar = st.button("üöÄ Executar")

if executar:
    if not api_key_configurada:
        st.error("‚ùå API Key n√£o encontrada")
        st.info("**Para desenvolvimento local:** Crie um arquivo .env com OPENAI_API_KEY=sua_chave")
        st.info("**Para produ√ß√£o:** Configure a API key nos Secrets do Streamlit Cloud")
        
    else:
        try:
            if opcao == "Tabela do Brasileir√£o":
                with st.spinner("Fazendo scraping da tabela do Brasileir√£o..."):
                    # Fazer scraping
                    import exemplo1_brasileirao
                    urls = ['https://ge.globo.com/futebol/brasileirao-serie-a/']
                    resultado = exemplo1_brasileirao.scrape_with_playwright(urls=urls, schema=exemplo1_brasileirao.schema)
                    
                    if resultado:
                        st.success("‚úÖ Scraping conclu√≠do com sucesso!")
                        
                        # Criar duas colunas
                        col1, col2 = st.columns([2, 1])
                        
                        with col1:
                            st.subheader("üìä TABELA DE CLASSIFICA√á√ÉO")
                            
                            # Tentar formatar como tabela do Brasileir√£o
                            df_tabela = formatar_tabela_brasileirao(resultado)
                            
                            if df_tabela is not None and not df_tabela.empty:
                                # Aplicar estilos na tabela (vers√£o compat√≠vel)
                                def colorir_posicoes(row):
                                    if row['Pos'] <= 4:
                                        return ['background-color: #d4edda'] * len(row)  # Verde claro - Libertadores
                                    elif row['Pos'] <= 6:
                                        return ['background-color: #fff3cd'] * len(row)  # Amarelo claro - Sul-Americana
                                    elif row['Pos'] >= 17:
                                        return ['background-color: #f8d7da'] * len(row)  # Vermelho claro - Rebaixamento
                                    else:
                                        return [''] * len(row)
                                
                                # Mostrar tabela estilizada (vers√£o compat√≠vel)
                                try:
                                    st.dataframe(
                                        df_tabela.style.apply(colorir_posicoes, axis=1),
                                        height=600
                                    )
                                except:
                                    # Fallback para vers√µes mais antigas do Streamlit
                                    st.dataframe(df_tabela, height=600)
                                
                                # Legenda
                                st.markdown("""
                                **Legenda:**
                                - üü¢ **Posi√ß√µes 1-4**: Classifica√ß√£o para Libertadores
                                - üü° **Posi√ß√µes 5-6**: Classifica√ß√£o para Sul-Americana  
                                - üî¥ **Posi√ß√µes 17-20**: Zona de rebaixamento
                                """)
                                
                            else:
                                st.warning("‚ö†Ô∏è N√£o foi poss√≠vel formatar os dados como tabela de classifica√ß√£o")
                                st.json(resultado)
                        
                        with col2:
                            st.subheader("ü•Ö ARTILHARIA")
                            
                            # Tentar extrair dados de artilharia
                            df_artilharia = formatar_artilharia(resultado)
                            
                            if df_artilharia is not None and not df_artilharia.empty:
                                st.dataframe(df_artilharia)
                            else:
                                st.info("‚ÑπÔ∏è Dados de artilharia n√£o encontrados nesta extra√ß√£o")
                        
                        # Se√ß√£o expand√≠vel com dados brutos
                        with st.expander("üîç Ver dados brutos (JSON)"):
                            st.json(resultado)
                            
                    else:
                        st.warning("‚ö†Ô∏è Nenhum dado foi extra√≠do. Verifique a URL ou o schema.")
                    
            elif opcao == "A√ß√µes (Big Caps)":
                with st.spinner("Fazendo scraping das a√ß√µes..."):
                    st.info("üöß Funcionalidade em desenvolvimento para o deploy")
                    
            elif opcao == "Agente inteligente":
                with st.spinner("Executando agente inteligente..."):
                    st.info("üöß Funcionalidade em desenvolvimento para o deploy")
                    
        except ImportError as e:
            st.error(f"‚ùå Erro de importa√ß√£o: {str(e)}")
            
        except Exception as e:
            st.error(f"‚ùå Erro durante a execu√ß√£o: {str(e)}")

# Sidebar din√¢mica baseada na op√ß√£o selecionada
with st.sidebar:
    st.header("‚ÑπÔ∏è Informa√ß√µes")
    
    if opcao == "Tabela do Brasileir√£o":
        st.write("**Brasileir√£o S√©rie A**")
        st.write("- Classifica√ß√£o em tempo real")
        st.write("- Dados extra√≠dos do Globo Esporte")
        st.write("  [https://ge.globo.com/futebol/brasileirao-serie-a/](https://ge.globo.com/futebol/brasileirao-serie-a/)")
        st.write("- Powered by LangChain + OpenAI")
        
    elif opcao == "A√ß√µes (Big Caps)":
        st.write("**A√ß√µes - Big Caps**")
        st.write("- Dados extra√≠dos da fonte:")
        st.write("  [https://br.tradingview.com/markets/stocks-brazil/market-movers-large-cap/](https://br.tradingview.com/markets/stocks-brazil/market-movers-large-cap/)")
        st.write("- Powered by LangChain + OpenAI")
        
    elif opcao == "Agente inteligente":
        st.write("**Agente Inteligente**")
        st.write("- Dados extra√≠dos da fonte:")
        st.write("- Qual time est√° na primeira coloca√ß√£o do brasileir√£o na tabela do site:")
        st.write("  [https://ge.globo.com/futebol/brasileirao-serie-a/](https://ge.globo.com/futebol/brasileirao-serie-a/)")
        st.write("- E o √∫ltimo colocado")
        st.write("- Powered by LangChain + OpenAI")
    
    # Informa√ß√µes do deploy
    st.markdown("---")
    st.caption("üöÄ Deploy: Streamlit Cloud")
    st.caption("üîß GitHub: seu-repositorio")